{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import nxneo4j as nx\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import warnings;\n",
    "import urllib.request\n",
    "import urllib, urllib.parse\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import urllib.parse\n",
    "import csv\n",
    "import unicodedata\n",
    "import io\n",
    "import time\n",
    "import numpy as np \n",
    "# output results of multiple statements in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# load libraries\n",
    "from multiprocessing import freeze_support\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import datetime, xlrd\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import pandas as pd # for later\n",
    "import spotipy.oauth2 as oauth2\n",
    "import time\n",
    "import csv\n",
    "import rdflib\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import datetime, xlrd\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.sparse import coo_matrix\n",
    "import array\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def unique(list1): \n",
    "    x = np.array(list1) \n",
    "    return np.unique(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_tracks_features1 =\"..//a_fm_data_prep_modif_user_item_tfidf_final.csv\"\n",
    "\n",
    "df_tracks_features1 = pd.read_csv(file_path_tracks_features1 , encoding= 'ISO-8859-1')\n",
    "\n",
    "users = df_tracks_features1[\"user_id\"].unique().tolist()\n",
    "user_count = len(users)\n",
    "\n",
    "urs = [users[i] for i in range(round(len(users)))] #0.8 ,0.5\n",
    "df = df_tracks_features1[df_tracks_features1['user_id'].isin(urs)]\n",
    "\n",
    "tracks = []\n",
    "for i in tqdm(urs):\n",
    "    temp = df[df[\"user_id\"] == i][\"item_id\"].tolist()\n",
    "    tracks.append(temp)  \n",
    "\n",
    "weight_all = []\n",
    "for i in tqdm(urs):\n",
    "    temp = df[df[\"user_id\"] == i][\"weight_all\"].tolist()\n",
    "    weight_all.append(temp)  \n",
    "\n",
    "weight_content = []\n",
    "for i in tqdm(urs):\n",
    "    temp = df[df[\"user_id\"] == i][\"weight_content\"].tolist()\n",
    "    weight_content.append(temp)  \n",
    "\n",
    "weight_context = []\n",
    "for i in tqdm(urs):\n",
    "    temp = df[df[\"user_id\"] == i][\"weight_context\"].tolist()\n",
    "    weight_context.append(temp)  \n",
    "\n",
    "interaction_description = []\n",
    "for i in tqdm(urs):\n",
    "    temp = df[df[\"user_id\"] == i][\"interaction_description\"].tolist()\n",
    "    interaction_description.append(temp)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.DataFrame({'user_id': urs,\n",
    "                             'item_id': tracks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the Factorization Machines model, we use LightFm libraries. \n",
    "# For more information about the libraries, you can visit the documentation page below:\n",
    "# https://making.lyst.com/lightfm/docs/home.html\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.data import Dataset\n",
    "from scipy.sparse import *\n",
    "from scipy import *\n",
    "\n",
    "urs  = np.array(interactions['user_id'])\n",
    "tracks  = np.array(interactions['item_id'])\n",
    "\n",
    "train_FM_ides = [1 for i in range(0,len(urs))]\n",
    "\n",
    "n = max(max(urs), max(tracks)) + 1\n",
    "interactions = coo_matrix((train_FM_ides, (urs, tracks)),shape=(n, n)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import mock\n",
    "\n",
    "rs = np.random.RandomState(3)\n",
    "interactions_train_FM, interactions_val_FM = random_train_test_split(interactions, test_percentage=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_ids_FM, track_train_ids_FM = interactions_train_FM.nonzero()\n",
    "user_val_ids_FM, track_val_ids_FM = interactions_val_FM.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urs_train = user_train_ids_FM\n",
    "tracks_train = track_train_ids_FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = max(max(urs_train), max(tracks_train)) + 1\n",
    "interactions_train = coo_matrix((train_FM_ides, (urs_train, tracks_train)),shape=(n, n)) \n",
    "interactions_all_train_weight = coo_matrix((weight_all_train, (urs_train, tracks_train)),shape=(n, n)) \n",
    "interactions_content_train_weight = coo_matrix((weight_content_train, (urs_train, tracks_train)),shape=(n, n)) \n",
    "interactions_context_train_weight = coo_matrix((weight_context_train, (urs_train, tracks_train)),shape=(n, n)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_c=30\n",
    "ep=20\n",
    "loss_= 'bpr' #warp\n",
    "l_r=0.005\n",
    "k_=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=no_c, loss=loss_, learning_rate=l_r)\n",
    "model.fit(interactions_train_FM, \n",
    "          epochs=ep)\n",
    "\n",
    "predictions1 = model.predict(user_val_ids_FM, track_val_ids_FM) \n",
    "\n",
    "train_precision_1 = precision_at_k(model, interactions_train_FM, k=k_).mean()\n",
    "test_precision_1 = precision_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "train_recall_1 = recall_at_k(model, interactions_train_FM,  k=k_).mean()\n",
    "test_recall_1 = recall_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "print(\"-------------------------------result----------------------------------\")\n",
    "print(\"General (without weights):\")\n",
    "print(\"train_precision_1 : \", train_precision_1)\n",
    "print(\"test_precision_1 : \", test_precision_1)\n",
    "print(\"train_recall_1 : \", train_recall_1)\n",
    "print(\"test_recall_1 : \", test_recall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(interactions_train_FM, \n",
    "          sample_weight= interactions_all_train_weight, \n",
    "          epochs=ep)\n",
    "\n",
    "predictions2 = model.predict(user_val_ids_FM, track_val_ids_FM) \n",
    "\n",
    "train_precision_2 = precision_at_k(model, interactions_train_FM, k=k_).mean()\n",
    "test_precision_2 = precision_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "train_recall_2 = recall_at_k(model, interactions_train_FM,  k=k_).mean()\n",
    "test_recall_2 = recall_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "print(\"With all weights:\")\n",
    "print(\"train_precision_2 : \", train_precision_2)\n",
    "print(\"test_precision_2 : \", test_precision_2)\n",
    "print(\"train_recall_2 : \", train_recall_2)\n",
    "print(\"test_recall_2 : \", test_recall_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(interactions_train_FM, \n",
    "          sample_weight= interactions_content_train_weight,  \n",
    "          epochs=ep)\n",
    "\n",
    "predictions3 = model.predict(user_val_ids_FM, track_val_ids_FM) \n",
    "\n",
    "train_precision_3 = precision_at_k(model, interactions_train_FM, k=k_).mean()\n",
    "test_precision_3 = precision_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "train_recall_3 = recall_at_k(model, interactions_train_FM,  k=k_).mean()\n",
    "test_recall_3 = recall_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "print(\"With content weights:\")\n",
    "print(\"train_precision_3 : \", train_precision_3)\n",
    "print(\"test_precision_3 : \", test_precision_3)\n",
    "print(\"train_recall_3 : \", train_recall_3)\n",
    "print(\"test_recall_3 : \", test_recall_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(interactions_train_FM, \n",
    "          sample_weight= interactions_context_train_weight,  \n",
    "          epochs=ep)\n",
    "\n",
    "predictions4 = model.predict(user_val_ids_FM, track_val_ids_FM) \n",
    "\n",
    "train_precision_4 = precision_at_k(model, interactions_train_FM, k=k_).mean()\n",
    "test_precision_4 = precision_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "\n",
    "train_recall_4 = recall_at_k(model, interactions_train_FM,  k=k_).mean()\n",
    "test_recall_4 = recall_at_k(model, interactions_val_FM).mean()\n",
    "\n",
    "print(\"With context weights:\")\n",
    "print(\"train_precision_4 : \", train_precision_4)\n",
    "print(\"test_precision_4 : \", test_precision_4)\n",
    "print(\"train_recall_4 : \", train_recall_4)\n",
    "print(\"test_recall_4 : \", test_recall_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
